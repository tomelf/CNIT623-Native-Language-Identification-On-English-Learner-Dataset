{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_train_score</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>params</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>model</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>errors</th>\n",
       "      <td>19.55%</td>\n",
       "      <td>14.28%</td>\n",
       "      <td>{'clf__kernel': 'rbf', 'clf__C': 10, 'union__e...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>charngrams</th>\n",
       "      <td>22.49%</td>\n",
       "      <td>13.82%</td>\n",
       "      <td>{'union__charngrams__reduce_dim__n_components'...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>funcwords</th>\n",
       "      <td>23.13%</td>\n",
       "      <td>14.02%</td>\n",
       "      <td>{'clf__kernel': 'rbf', 'clf__C': 20, 'union__f...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>posngrams</th>\n",
       "      <td>22.48%</td>\n",
       "      <td>14.65%</td>\n",
       "      <td>{'clf__C': 20, 'union__posngrams__tfidf__ngram...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>wordngrams</th>\n",
       "      <td>19.59%</td>\n",
       "      <td>13.82%</td>\n",
       "      <td>{'clf__C': 20, 'union__wordngrams__tfidf__ngra...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>d2v</th>\n",
       "      <td>36.72%</td>\n",
       "      <td>15.71%</td>\n",
       "      <td>{'clf__C': 10, 'clf__kernel': 'rbf'}</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           mean_train_score mean_test_score  \\\n",
       "model                                         \n",
       "errors               19.55%          14.28%   \n",
       "charngrams           22.49%          13.82%   \n",
       "funcwords            23.13%          14.02%   \n",
       "posngrams            22.48%          14.65%   \n",
       "wordngrams           19.59%          13.82%   \n",
       "d2v                  36.72%          15.71%   \n",
       "\n",
       "                                                       params  \n",
       "model                                                          \n",
       "errors      {'clf__kernel': 'rbf', 'clf__C': 10, 'union__e...  \n",
       "charngrams  {'union__charngrams__reduce_dim__n_components'...  \n",
       "funcwords   {'clf__kernel': 'rbf', 'clf__C': 20, 'union__f...  \n",
       "posngrams   {'clf__C': 20, 'union__posngrams__tfidf__ngram...  \n",
       "wordngrams  {'clf__C': 20, 'union__wordngrams__tfidf__ngra...  \n",
       "d2v                      {'clf__C': 10, 'clf__kernel': 'rbf'}  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "errors = pd.read_csv('task3_grid_search_errors.csv')\n",
    "charngrams = pd.read_csv('task3_grid_search_charngrams.csv')\n",
    "d2v = pd.read_csv('task3_grid_search_doc2vec.csv')\n",
    "funcwords = pd.read_csv('task3_grid_search_funcwords.csv')\n",
    "posngrams = pd.read_csv('task3_grid_search_posngrams.csv')\n",
    "wordngrams = pd.read_csv('task3_grid_search_wordngrams.csv')\n",
    "\n",
    "df = pd.DataFrame([\n",
    "    errors[errors['rank_test_score']==1][['mean_train_score', 'mean_test_score', 'params']].iloc[0],\n",
    "    charngrams[charngrams['rank_test_score']==1][['mean_train_score', 'mean_test_score', 'params']].iloc[0],\n",
    "    funcwords[funcwords['rank_test_score']==1][['mean_train_score', 'mean_test_score', 'params']].iloc[0],\n",
    "    posngrams[posngrams['rank_test_score']==1][['mean_train_score', 'mean_test_score', 'params']].iloc[0],\n",
    "    wordngrams[wordngrams['rank_test_score']==1][['mean_train_score', 'mean_test_score', 'params']].iloc[0],\n",
    "    d2v[d2v['rank_test_score']==1][['mean_train_score', 'mean_test_score', 'params']].iloc[0]\n",
    "])\n",
    "\n",
    "df['model'] = pd.Series([\"errors\",\"charngrams\",\"funcwords\",\"posngrams\",\"wordngrams\",\"d2v\"], index=df.index)\n",
    "df[\"mean_train_score\"] = pd.Series([\"{0:.2f}%\".format(val * 100) for val in df['mean_train_score']], index=df.index)\n",
    "df[\"mean_test_score\"] = pd.Series([\"{0:.2f}%\".format(val * 100) for val in df['mean_test_score']], index=df.index)\n",
    "df = df.reindex(columns=[\"model\", \"mean_train_score\", \"mean_test_score\", 'params'])\n",
    "df.set_index(\"model\", inplace=True)\n",
    "df.to_csv('task3_grid_search_results.csv')\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "import re\n",
    "import pandas as pd\n",
    "\n",
    "files = [f for f in listdir(\"./\") if isfile(join(\"./\", f)) and f.endswith(\"csv\") and f.startswith(\"task3_test\")]\n",
    "df_language = []\n",
    "df_precision = []\n",
    "df_recall = []\n",
    "df_f1 = []\n",
    "df_support = []\n",
    "df_overall = []\n",
    "for file in files:\n",
    "    feature, type = re.match(\"task3_test_([^_]+)_([^_]+).csv\", file).groups()\n",
    "    if type not in [\"train\", \"test\"]:\n",
    "        continue\n",
    "    df = pd.read_csv(file)\n",
    "    \n",
    "    df[\"overall\"] = pd.Series([\"({} {} {})\".format(\\\n",
    "                                    str(row[\"precision\"]).lstrip('0'), \n",
    "                                    str(row[\"recall\"]).lstrip('0'), \n",
    "                                    str(row[\"f1-score\"]).lstrip('0')\n",
    "                                ) \\\n",
    "                                for idx, row \\\n",
    "                                in df.iterrows()], index=df.index)\n",
    "    \n",
    "    df_language = [\"feature\", \"type\"] + df[\"language\"].tolist()\n",
    "    df_precision.append([feature, type]+df[\"precision\"].tolist())\n",
    "    df_recall.append([feature, type]+df[\"recall\"].tolist())\n",
    "    df_f1.append([feature, type]+df[\"f1-score\"].tolist())\n",
    "    df_support.append([feature, type]+df[\"support\"].tolist())\n",
    "    df_overall.append([feature, type]+df[\"overall\"].tolist())\n",
    "pd.DataFrame(df_precision, columns=df_language).sort_values(by=[\"feature\", \"type\"], ascending=False).to_csv(\"task3_test_df_precision.csv\")\n",
    "pd.DataFrame(df_recall, columns=df_language).sort_values(by=[\"feature\", \"type\"], ascending=False).to_csv(\"task3_test_df_recall.csv\")\n",
    "pd.DataFrame(df_f1, columns=df_language).sort_values(by=[\"feature\", \"type\"], ascending=False).to_csv(\"task3_test_df_f1.csv\")\n",
    "pd.DataFrame(df_overall, columns=df_language).sort_values(by=[\"feature\", \"type\"], ascending=False).to_csv(\"task3_test_df_overall.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "import re\n",
    "import pandas as pd\n",
    "\n",
    "files = [f for f in listdir(\"./\") if isfile(join(\"./\", f)) and f.endswith(\"csv\") and f.startswith(\"task3_doc2vec_lstm_results_\")]\n",
    "df_language = []\n",
    "df_precision = []\n",
    "df_recall = []\n",
    "df_f1 = []\n",
    "df_support = []\n",
    "df_overall = []\n",
    "for file in files:\n",
    "    feature, type = re.match(\"task3_doc2vec_lstm_results_([^_]+)_([^_]+).csv\", file).groups()\n",
    "    if type not in [\"train\", \"test\"]:\n",
    "        continue\n",
    "    df = pd.read_csv(file)\n",
    "    \n",
    "    df[\"overall\"] = pd.Series([\"({} {} {})\".format(\\\n",
    "                                    str(row[\"precision\"]).lstrip('0'), \n",
    "                                    str(row[\"recall\"]).lstrip('0'), \n",
    "                                    str(row[\"f1-score\"]).lstrip('0')\n",
    "                                ) \\\n",
    "                                for idx, row \\\n",
    "                                in df.iterrows()], index=df.index)\n",
    "    \n",
    "    df_language = [\"feature\", \"type\"] + df[\"language\"].tolist()\n",
    "    df_precision.append([feature, type]+df[\"precision\"].tolist())\n",
    "    df_recall.append([feature, type]+df[\"recall\"].tolist())\n",
    "    df_f1.append([feature, type]+df[\"f1-score\"].tolist())\n",
    "    df_support.append([feature, type]+df[\"support\"].tolist())\n",
    "    df_overall.append([feature, type]+df[\"overall\"].tolist())\n",
    "pd.DataFrame(df_precision, columns=df_language).sort_values(by=[\"feature\", \"type\"], ascending=False).to_csv(\"task3_doc2vec_lstm_results_df_precision.csv\")\n",
    "pd.DataFrame(df_recall, columns=df_language).sort_values(by=[\"feature\", \"type\"], ascending=False).to_csv(\"task3_doc2vec_lstm_results_df_recall.csv\")\n",
    "pd.DataFrame(df_f1, columns=df_language).sort_values(by=[\"feature\", \"type\"], ascending=False).to_csv(\"task3_doc2vec_lstm_results_df_f1.csv\")\n",
    "pd.DataFrame(df_overall, columns=df_language).sort_values(by=[\"feature\", \"type\"], ascending=False).to_csv(\"task3_doc2vec_lstm_results_df_overall.csv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
